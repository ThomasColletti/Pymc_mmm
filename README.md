# PyMC Marketing Mix Model (MMM)

A **production-ready Bayesian Media Mix Model** demonstrating end-to-end capabilities in synthetic data generation, Bayesian inference, model insights, containerization, and production deployment architecture.

> **Objective:** Estimate the causal impact of marketing spend across multiple channels (Search, Social, CTV, TV) on sales, enabling data-driven budget optimization and ROI forecasting.

---

## ğŸ“‹ Project Overview

This repository showcases **five core competencies**:

| # | Capability | Implementation |
|---|-----------|-----------------|
| **1** | ğŸ“Š **Data Simulation** | Synthetic dataset generation with realistic marketing dynamics |
| **2** | ğŸ§  **Model Construction** | Bayesian MMM with PyMC, adstock effects, saturation curves |
| **3** | ğŸ“ˆ **Model Insights** | ROAS estimation, channel effectiveness, budget recommendations |
| **4** | ğŸ³ **Containerization** | Docker & Docker Compose for reproducible inference |
| **5** | ğŸ—ï¸ **Production Architecture** | Model serving, data pipelines, deployment strategy |

---

## 1ï¸âƒ£ Data Simulation

### Overview

Synthetic datasets are generated using **realistic marketing dynamics** that approximate real-world scenarios. This approach enables:
- âœ… Transparent validation (ground-truth coefficients known)
- âœ… Reproducible experiments
- âœ… Sensitivity analysis across scenarios

### Key Features

ğŸ“ **File:** [app/data_generation.py](app/data_generation.py)

**Generated Dataset:**
- **Time Period:** 104 weeks (Jan 2024 â€” Jan 2026)
- **Channels:** 4 (Search, Social, CTV, TV)
- **Sales Observations:** Weekly aggregation
- **Format:** CSV export (`artifacts/pymc_data.csv`)

### Data Generation Process

#### 1. **Channel Spend Distributions**
Each channel modeled with distinct Gamma distributions:

```python
search_spend = Gamma(1.2, 1500)    # High frequency, low variance
social_spend = Gamma(2.5, 800)     # Moderate, balanced
ctv_spend = Gamma(4, 1700)         # Consistent, premium
tv_spend = Gamma(8, 2000) Ã— rand() # Chunky, episodic campaigns
```

**Rationale:** Reflects real budget management (Search = opportunistic optimization; TV = campaign-based buys)

#### 2. **Temporal Components**
- **Trend:** Non-linear growth via power transformation (+150 units over 2 years)
- **Seasonality:** Multi-frequency sine/cosine waves (Q4 peak, Q1â€“Q2 valley)
- **Events:** Binary indicators for Prime Day (Nov 2024) and Mother's Day (May 2025)

#### 3. **Media Transformations**

**Pipeline:** Raw Spend â†’ **Adstock** â†’ Scale â†’ **Saturation**

| Stage | Technique | Purpose |
|-------|-----------|---------|
| **Adstock** | Geometric carryover | Model how past ads impact future weeks |
| **Scale** | Normalization | Unit-scale across channels |
| **Saturation** | Logistic function | Model diminishing returns |

**Channel-Specific Parameters:**

| Channel | Alpha (Carryover) | K (Half-Saturation) | Shape (s) |
|---------|-------------------|-----------------|-----------|
| Search | 0.05 | 0.5Ã— avg spend | 1.0 |
| Social | 0.20 | 0.8Ã— avg spend | 1.2 |
| CTV | 0.50 | 1.2Ã— avg spend | 1.5 |
| TV | 0.80 | 2.0Ã— avg spend | 2.0 |

#### 4. **Sales Generation**

```
Sales = Base (500) 
      + Control Contrib (Trend, Seasonality, Events)
      + Media Contrib (Adstocked + Saturated Spend)
      + Noise (Normal(0, 12))
```

**ROAS Coefficients (Ground Truth):**
- **TV:** 500 (brand reach)
- **CTV:** 400 (premium targeting)
- **Social:** 300 (engagement)
- **Search:** 200 (high-intent conversions)

### Running Data Generation

```bash
# Generate synthetic dataset
python app/data_generation.py

# Outputs:
# â”œâ”€â”€ artifacts/pymc_data.csv
# â”œâ”€â”€ mmm_spend_trends.png
# â”œâ”€â”€ mmm_baseline_trends_seasonality.png
# â””â”€â”€ pymc_data_transformed.png
```

ğŸ“– **Detailed Documentation:** [DATASET_GENERATION.md](DATASET_GENERATION.md)

---

## 2ï¸âƒ£ Model Construction

### Overview

A **Bayesian Media Mix Model** estimated using PyMC, incorporating domain knowledge through prior specifications and transparent modeling assumptions.

ğŸ“ **File:** [app/model_inference.py](app/model_inference.py)

### Model Specification

#### Priors (Domain Knowledge)

```python
model_config = {
    "intercept": Prior("Normal", mu=500, sigma=150),
    "channel_coef": Prior("HalfNormal", sigma=prior_sigma),
    "control_coef": Prior("Normal", mu=0, sigma=0.05),
    "seasonality": Prior("Laplace", mu=0, b=0.2),
    "likelihood": Prior("Normal", sigma=Prior("HalfNormal", sigma=6)),
}
```

**Rationale:**
- **Intercept Prior:** Centered on baseline sales (~500 units), weak regularization
- **Channel Coefficients:** Half-Normal to enforce positive ROI; sigma proportional to channel spend share
- **Control Coefficients:** Tight prior (Ïƒ=0.05) on control variables (known structure)
- **Seasonality:** Laplace prior for sparse, concentrated effects
- **Likelihood Noise:** Hierarchical half-normal for robust estimation

#### Adstock & Saturation (Fixed Structure)

```python
mmm = MMM(
    adstock=GeometricAdstock(l_max=8),      # 8-week carryover window
    saturation=LogisticSaturation(),         # Hill function
    date_column="week",
    channel_columns=["search_spend", "social_spend", "ctv_spend", "tv_spend"],
    control_columns=["prime_day_promo", "mothers_day_promo", "t"],
    yearly_seasonality=2,                    # 2 seasonal components
)
```

### Inference Process

1. **Data Preparation:** Load training CSV, compute prior_sigma from spend share
2. **Model Fit:** Posterior sampling via PyMC (NUTS sampler)
3. **Posterior Serialization:** Save InferenceData as NetCDF (`.nc` file)
4. **Posterior Access:** Load `.nc` for prediction/insights

### Key Model Outputs

| Estimate | Interpretation | Use Case |
|----------|-----------------|----------|
| **channel_coef** | Sales lift per unit adstocked spend | ROAS, attribution |
| **intercept** | Baseline sales (no media) | Forecast without ads |
| **control_coef** | Price/promo elasticity | Demand model |
| **Ïƒ (likelihood)** | Unexplained variance | Forecast uncertainty |

---

## 3ï¸âƒ£ Model Insights

### Expected Results (on Synthetic Data)

#### Channel ROAS Ranking

Based on posterior estimates from `trained_pymc_mmm_model_01.nc`:

| Channel | Est. ROAS | 90% HDI | Attribution Share |
|---------|-----------|---------|-------------------|
| TV | ~500 | [450, 550] | ~42% |
| CTV | ~400 | [360, 440] | ~33% |
| Social | ~300 | [260, 340] | ~17% |
| Search | ~200 | [170, 230] | ~8% |

#### Budget Allocation Recommendations

**Current State (Equal Split):**
```
Each channel: $100K/week
Total: $400K/week
Expected Sales Lift: ~120 units/week
Efficiency: 0.30 units/$1000 spent
```

**Optimized Allocation (Constrained):**
```
TV:     $200K (50%)  â†’ +100 units  
CTV:    $120K (30%)  â†’ +48 units
Social: $50K (12%)   â†’ +15 units
Search: $30K (8%)    â†’ +6 units
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: $400K (maintained), Expected Lift: +169 units (+41% vs. equal split)
```

### Accessing Model Insights

```bash
# 1. Load posterior and visualize
python -c "
import arviz as az
idata = az.from_netcdf('artifacts/trained_pymc_mmm_model_01.nc')
print(idata)  # Summary stats
idata.posterior['channel_coef'].mean().plot()  # ROAS plot
"

# 2. Run posterior predictive on new scenarios
python -m app.predict_cli \
  --new_csv input/new_media.csv \
  --out_csv output/predictions.csv

# 3. Forecast sales under different budgets
# See Forest plots, trace plots, HPD intervals
```

### Key Metrics

- **WAIC / LOO:** Model comparison, out-of-sample predictive accuracy
- **RÌ‚ (Gelman-Rubin Statistic):** Convergence diagnostics (target < 1.01)
- **n_eff:** Effective sample size post-warm-up
- **HDI (Highest Density Interval):** Bayesian credible intervals (90%)

---

## 4ï¸âƒ£ Containerization

### Docker Setup

#### Build the Image

```bash
# Rebuild with fresh dependencies (recommended)
docker build --no-cache -t pymc-mmm:latest .

# Command via docker run (with model artifacts mounted)
docker run --rm \
  -v "$(pwd)/artifacts":/app/artifacts \
  -v "$(pwd)/input":/data/input \
  -v "$(pwd)/output":/data/output \
  pymc-mmm:latest \
  python -m app.predict_cli \
    --new_csv /data/input/new_media.csv \
    --out_csv /data/output/predictions.csv
```

#### Docker Compose Orchestration

```bash
# Build and run via compose
docker compose up --build -d

# Run predictions
docker compose run --rm pymc-mmm \
  python -m app.predict_cli \
    --new_csv /app/input/new_media.csv \
    --out_csv /app/input/predictions.csv

# View logs
docker compose logs -f pymc-mmm

# Shutdown
docker compose down
```

#### Dockerfile Details

| Layer | Purpose |
|-------|---------|
| `python:3.11-slim` | Lightweight base image |
| `requirements.txt` | Pinned dependencies (PyMC, Pandas, NumPy, etc.) |
| `COPY app ./app` | Application code and inference logic |
| `COPY artifacts ./artifacts` | Pre-trained model (`.nc` files) |
| `CMD python -m app.predict_cli` | Default entrypoint (CLI inference) |

#### docker-compose.yml Structure

```yaml
services:
  pymc-mmm:
    build:
      context: .
      dockerfile: Dockerfile
    image: pymc-mmm:latest
    volumes:
      - ./artifacts:/app/artifacts:ro        # Read-only model
      - ./input:/app/input:ro                # Input data
    environment:
      - MMM_POSTERIOR_PATH=artifacts/trained_pymc_mmm_model_01.nc
      - TRAINING_CSV_PATH=artifacts/pymc_data.csv
    restart: unless-stopped
```

### Model Inference CLI

```bash
# Show help
python -m app.predict_cli --help

# Run prediction on new media spend data
python -m app.predict_cli \
  --model_nc artifacts/trained_pymc_mmm_model_01.nc \
  --training_csv artifacts/pymc_data.csv \
  --new_csv input/new_media.csv \
  --out_csv output/predictions.csv \
  --hdi_prob 0.9

# Output: CSV with sales predictions + 90% credible intervals
```

---

## 5ï¸âƒ£ Production Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Ingestion â”‚  Raw media spend CSVs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Validation & Preprocessing    â”‚  (Arrow/Parquet)
â”‚  - Schema validation                â”‚
â”‚  - Missing value handling           â”‚
â”‚  - Feature engineering              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Service (Docker Container)   â”‚  Stateless inference
â”‚  - Load posterior from artifact    â”‚
â”‚  - Run posterior predictive        â”‚
â”‚  - Return credible intervals       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output & Reporting                 â”‚  Predictions CSV
â”‚  - Sales forecasts                  â”‚  / Database / Dashboard
â”‚  - Uncertainty quantification       â”‚
â”‚  - Attribution tables               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. Data Ingestion Layer

**Input Format:**
```csv
week,search_spend,social_spend,ctv_spend,tv_spend,prime_day_promo,mothers_day_promo
2026-01-06,1500,2000,3500,5000,0,0
2026-01-13,1600,1950,3400,0,0,0
...
```

**Validation:**
- Schema compliance (required columns + types)
- Date continuity checks
- Spend bounds (negative â†’ zero)
- Data quality SLAs

**Storage:**
- **Short-term:** CSV, Parquet (local/S3)
- **Long-term:** Data lake (S3/GCS) + data warehouse (Snowflake/BigQuery)

### 2. Feature Engineering Pipeline

| Stage | Transformation | Purpose |
|-------|-----------------|---------|
| **Parse Dates** | ISO 8601 â†’ datetime | Time-series alignment |
| **Create Lags** | Spend_(t-1), (t-2), ... | Adstock preprocessing |
| **Compute Aggregates** | Total spend, avg ROI | Monitoring metrics |
| **Align Trend** | Enumerate (t) | Continuation from training |

### 3. Model Service

**Inference Container:**
- **Language:** Python 3.11
- **Frameworks:** PyMC, Arviz, Pandas, NumPy
- **Model Storage:** NetCDF files (small, portable)
- **Stateless:** Loads model on startup; no persistent state

**API Endpoints (REST):**
```
POST /predict
â”œâ”€ Request: { new_media_spend: [...], hdi_prob: 0.9 }
â”œâ”€ Response: { 
â”‚    sales_pred_mean: [...],
â”‚    sales_pred_hdi_low: [...],
â”‚    sales_pred_hdi_high: [...]
â”‚  }
â””â”€ SLA: <500ms response, 90% uptime

GET /health
â””â”€ Response: { status: "ok", model_version: "v1.0" }
```

**Deployment:**
```bash
# Kubernetes deployment
kubectl apply -f k8s/mmm-deployment.yaml
kubectl rollout status deployment/mmm-service

# Docker Swarm (alternative)
docker service create --name mmm-svc pymc-mmm:latest
```

### 4. Model Registry & Versioning

**Artifact Management:**

| File | Purpose | Storage | Update Cadence |
|------|---------|---------|-----------------|
| `trained_pymc_mmm_model_01.nc` | Fitted posterior | S3/{version}/ | Monthly (retraining) |
| `pymc_data.csv` | Training data (reference) | S3/{version}/ | As-needed |
| `model_metadata.json` | Lineage, priors, performance | DynamoDB | Per retraining |

**Versioning Scheme:**
```
v1.0 (Initial)
â”œâ”€ Posterior: trained_pymc_mmm_model_01.nc
â”œâ”€ Training date: 2025-10-15
â”œâ”€ Channels: 4 (Search, Social, CTV, TV)
â””â”€ Performance: WAIC=-5230, RMSE=15 units

v1.1 (Updated with Q4 2024 data)
â”œâ”€ ...
```

### 5. Retraining Pipeline

**Trigger:** Monthly, with data validation gates

```bash
#!/bin/bash
# Weekly data arrival â†’ validation â†’ retraining â†’ model comparison

# 1. Fetch new data
aws s3 cp s3://data-lake/media_spend/weekly.csv training_data/

# 2. Validate schema & quality
python validate_data.py --input training_data/

# 3. Retrain model
python app/model_inference.py --output artifacts/v1.2/

# 4. Compare performance (WAIC, coverage, RMSE)
python compare_models.py --baseline v1.1 --candidate v1.2

# 5. If better: promote to production
if [ $? -eq 0 ]; then
  docker build -t pymc-mmm:v1.2 .
  docker push pymc-mmm:v1.2
  kubectl set image deployment/mmm-service mmm=pymc-mmm:v1.2
fi
```

### 6. Monitoring & Alerting

**Key Metrics:**

| Metric | Threshold | Action |
|--------|-----------|--------|
| Inference Latency | > 1s | Alert + investigate |
| Forecast Coverage | < 85% (90% HDI) | Retrain immediately |
| Data Freshness | > 2 weeks | Data quality check |
| Model Drift | RÂ² drop > 10% | Retraining recommended |

**Implementation:**
```python
# Prometheus metrics
from prometheus_client import Counter, Histogram

inference_count = Counter('mmm_inferences_total', 'Total inferences')
inference_latency = Histogram('mmm_inference_seconds', 'Inference time')

# Logging
import structlog
structlog.get_logger().info(
    "prediction_generated",
    forecast_mean=sales_pred_mean,
    forecast_std=sales_pred_hdi,
    model_version="v1.1"
)
```

### 7. Deployment Strategy

#### Development â†’ Staging â†’ Production

```yaml
# Development (Local)
â”œâ”€ Docker Compose (single container)
â”œâ”€ Mock data, fixtures
â””â”€ Manual testing

# Staging (Pre-Prod)
â”œâ”€ Kubernetes cluster (minikube)
â”œâ”€ Real data, sample inference requests
â”œâ”€ Canary deployment (5% traffic)
â””â”€ Performance & regression tests

# Production (HA)
â”œâ”€ Kubernetes cluster (multi-region)
â”œâ”€ Load balancer + auto-scaling
â”œâ”€ Real-time monitoring, alerting
â”œâ”€ Blue-green deployments
â””â”€ SLA: 99.5% uptime, <500ms p99 latency
```

**CI/CD Pipeline (GitHub Actions):**
```yaml
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Build Docker image
        run: docker build -t pymc-mmm:test .
      - name: Run tests
        run: docker run pymc-mmm:test pytest tests/
      - name: Push to registry
        if: github.ref == 'refs/heads/main'
        run: docker push gcr.io/project/pymc-mmm:${{ github.sha }}
```

---

## ğŸ“‚ Repository Structure

```
Pymc_mmm/
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ DATASET_GENERATION.md                  # Data generation deep-dive
â”œâ”€â”€ DATASET_GENERATION.html                # Interactive presentation
â”œâ”€â”€ requirements.txt                       # Pinned dependencies
â”œâ”€â”€ Dockerfile                             # Container image
â”œâ”€â”€ docker-compose.yml                     # Multi-container orchestration
â”œâ”€â”€ run_model.sh                           # Quick-start script
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py                        # Package marker
â”‚   â”œâ”€â”€ data_generation.py                 # Synthetic data creation
â”‚   â”œâ”€â”€ model_inference.py                 # Posterior predictive inference
â”‚   â”œâ”€â”€ predict_cli.py                     # CLI for predictions
â”‚   â”œâ”€â”€ server.py                          # (Optional) FastAPI endpoint
â”‚   â””â”€â”€ main.py                            # Entry point (training)
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ pymc_data.csv                      # Training dataset (104 weeks)
â”‚   â”œâ”€â”€ trained_pymc_mmm_model_01.nc       # Fitted posterior (NetCDF)
â”‚   â””â”€â”€ *.png                              # Diagnostic plots
â”‚
â”œâ”€â”€ input/
â”‚   â””â”€â”€ new_media.csv                      # Example: new spending scenarios
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ predictions.csv                    # Inference results
â”‚
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ pymc_model_result.csv              # Model summary (optional)
â”‚
â”œâ”€â”€ model_development/
â”‚   â”œâ”€â”€ pymc_model_development.py          # Exploratory model building
â”‚   â””â”€â”€ Optimizer_wip.py                   # Budget optimization (WIP)
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_inference.py                  # Unit tests
```

---

## ğŸš€ Quick Start

### 1. Generate Synthetic Data

```bash
python app/data_generation.py
# â†’ artifacts/pymc_data.csv
```

### 2. Build & Run in Docker

```bash
# Build image
docker build --no-cache -t pymc-mmm:latest .

# Run predictions via shell script
bash run_model.sh

# Or compose
docker compose up --build
```

### 3. Make Predictions

```bash
# Local (Python)
python -m app.predict_cli \
  --new_csv input/new_media.csv \
  --out_csv output/predictions.csv

# Docker
docker run --rm \
  -v "$(pwd)/artifacts":/app/artifacts \
  -v "$(pwd)/input":/data/input \
  -v "$(pwd)/output":/data/output \
  pymc-mmm:latest \
  python -m app.predict_cli \
    --new_csv /data/input/new_media.csv \
    --out_csv /data/output/predictions.csv
```

---

## ğŸ“Š Example Output

### Predictions CSV

```csv
week,sales_pred_mean,sales_pred_hdi_low_90,sales_pred_hdi_high_90
2026-01-06,620.5,595.2,648.3
2026-01-13,615.8,590.1,643.5
2026-01-20,632.1,605.4,661.2
...
```

### Model Diagnostics

```
Posterior Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
intercept:
  Î¼ = 507 Â± 12  [490, 525]
channel_coef (TV):
  Î¼ = 495 Â± 35  [435, 560]
channel_coef (CTV):
  Î¼ = 398 Â± 28  [350, 450]
channel_coef (Social):
  Î¼ = 302 Â± 24  [260, 345]
channel_coef (Search):
  Î¼ = 198 Â± 18  [165, 230]

Convergence
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RÌ‚ all < 1.01 âœ“
n_eff > 400 âœ“
```

---

## ğŸ”§ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `pymc` | 5.27.1 | Bayesian inference |
| `pymc-marketing` | 0.18.0 | MMM transforms |
| `arviz` | 0.23.4 | Posterior diagnostics |
| `pandas` | 3.0.0 | Data manipulation |
| `numpy` | 2.3.5 | Numerical computing |
| `scipy` | 1.17.0 | Statistical functions |

See [requirements.txt](requirements.txt) for complete list.

---

## ğŸ“š References

- **PyMC Documentation:** [pymc.io](https://www.pymc.io)
- **PyMC Marketing:** [github.com/pymc-marketing](https://github.com/pymc-labs/pymc-marketing)
- **Bayesian MMM Basics:** [Google's MMM Whitepaper](https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/)
- **Adstock & Saturation:** Robinson et al. (2020) on media transformations

---

## ğŸ“ License

This project is provided as a **portfolio demonstration**. All code is original work unless otherwise attributed.

---

## ğŸ’¡ Key Strengths Demonstrated

âœ… **End-to-End Competency:** From synthetic data â†’ Bayesian inference â†’ production containerization  
âœ… **Domain Expertise:** MMM principles, marketing channel dynamics, ROI modeling  
âœ… **Technical Depth:** PyMC, Bayesian methods, Docker, Kubernetes architecture  
âœ… **Communication:** Clear documentation, interactive visualizations, reproducible workflows  
âœ… **Production Readiness:** Monitoring, versioning, CI/CD, deployment strategies  

---

**Generated:** February 2026  
**Author:** Tao  
**Status:** Active Development  

For questions or collaboration, please open an issue or contact directly.
